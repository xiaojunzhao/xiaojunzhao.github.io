---
layout: post
title: Understanding of Long Short Term Memory Neural Network and Python Implementation
permalink: blog/LSTM/
---

<p style='text-align: justify;'>LSTMs, short for Long Short Term Memory networks, is a variant of Recurrent Neural Networks and introduced to solve the vanishing gradient problem of RNN when we need to backpropagate error across many timestamps, in other words, it is capable of learning long-term dependencies. This blog will quickly go over the structure of LSTM and how it works.we will focus on deriving gradients step by step in details.At last, we'll implement a simple LSTM model using pure python code. </p>

<p style='text-align: justify;'>Firstly, let's understand the architecture of LSTM and how feedforward pass works. The picture below is from <a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/">colah's blog</a> </p>
<center>
<img src="/images/lstm_structure.png" class="center" style="width: 70%; height: 70%" >
</center>
<p style='text-align: justify;'>Information passes through three gates in each of the LSTM node across timestamps.</p>

1. Forget Gate: 
<center>
<img src="/images/forget.png" class="center" style="width: 70%; height: 70%" >
</center>

<p style='text-align: justify;'>The forget gate \(f_t\) is capable of deciding which information to forget from the previous cell state \(C_{t-1}\), because the output of the sigmoid function \(\sigma\) is a single value between 0 and 1. Multiplying this value with an element of \(C_{t-1}\) means how much information we're going to throw away, or put in another way, how much informatio we're going to keep.  Here, we notice that we concate the previous hidden state \(h_{t-1}\) with the input vector \(X_{t}\) together. Let's assume the input \(X_{t}\) is a \(D \times 1\) vector, and \(h_{t-1}\) has \(H\) neurons, then the concated vector \([h_{t-1},X_{t}]\) is a \((H+D) \times 1\) vector. </p>

2. Input Gate: 
<center>
<img src="/images/input.png" class="center" style="width: 70%; height: 70%" >
</center>

<p style='text-align: justify;'> The input gate involves
</p>
